{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ff3c040",
   "metadata": {},
   "source": [
    "Gökçe Şahin\n",
    "090190306\n",
    "sahingo19@itu.edu.tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "f0567031",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import wbgapi as wb\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import yfinance as yf\n",
    "\n",
    "from statsmodels.formula.api import ols\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53c03e0-c8c7-40bb-a814-c4de469821b7",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "For this question use the World Bank Data for Turkey for the following indicators. Use [wbgapi](https://pypi.org/project/wbgapi/) for getting the data.\n",
    "\n",
    "* [Literacy rate, adult female (SE.ADT.LITR.FE.ZS)](https://data.worldbank.org/indicator/SE.ADT.LITR.FE.ZS)\n",
    "* [Labor force, female (SL.TLF.TOTL.FE.ZS)](https://data.worldbank.org/indicator/SL.TLF.TOTL.FE.ZS)\n",
    "* [Poverty headcount ratio at national poverty lines (SI.POV.NAHC)](https://data.worldbank.org/indicator/SI.POV.NAHC)\n",
    "* [Current health expenditure per capita (SH.XPD.CHEX.PC.CD)](https://data.worldbank.org/indicator/SH.XPD.CHEX.PC.CD)\n",
    "* [GDP per capita (NY.GDP.PCAP.CD)](https://data.worldbank.org/indicator/NY.GDP.PCAP.CD)\n",
    "* [Mortality rate, under-5 (SH.DYN.MORT)](https://data.worldbank.org/indicator/SH.DYN.MORT)\n",
    "\n",
    "\n",
    "Using the [statsmodels](https://www.statsmodels.org/stable/index.html) library write the best linear regression model using child mortality as the dependent variable while the rest are considered as independent variables. Pay particular attention to the fact that the order of the variables put into the model significantly impacts the performance of the model. Choose the best model by considering\n",
    "\n",
    "* with the minimum number of variables and their interactions,\n",
    "* with the optimal ordering of the independent variables and their interactions,\n",
    "* $R^2$-score of the model,\n",
    "* statistical significance of the model coefficients,\n",
    "* ANOVA analysis of the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "31354004",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(df, cntry, name):\n",
    "    tmp = df[['time','value']][df['economy'] == cntry]\n",
    "    tmp.index = tmp.time\n",
    "    del tmp['time']\n",
    "    tmp.columns = [[name]]\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "f99e8694",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vars_mor(cntry, dfs, vars):\n",
    "    arr = [extract(dfs[i], cntry, vars[i]) for i in range(len(vars))]\n",
    "    res = arr[0].join(arr[1:6])\n",
    "    res.dropna(inplace=True)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "858c218a",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_apis = {\n",
    "    'literacy': 'SE.ADT.LITR.FE.ZS',\n",
    "    'labor': 'SL.TLF.TOTL.FE.ZS',\n",
    "    'poverty': 'SI.POV.NAHC',\n",
    "    'health': 'SH.XPD.CHEX.PC.CD',\n",
    "    'GDP': 'NY.GDP.PCAP.CD',\n",
    "    'mortality': 'SH.DYN.MORT'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "a3ec536f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = ['literacy', 'labor', 'mortality']\n",
    "# independent variables + dependent variable (mortality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "e3f98a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [pd.DataFrame(list(wb.data.fetch(api))) for api in [var_apis[var] for var in vars]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "01bfd781-552b-4005-bc26-f3d3a7008e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              mortality   R-squared:                       0.977\n",
      "Model:                            OLS   Adj. R-squared:                  0.973\n",
      "Method:                 Least Squares   F-statistic:                     252.1\n",
      "Date:                Mon, 07 Nov 2022   Prob (F-statistic):           1.58e-10\n",
      "Time:                        23:28:17   Log-Likelihood:                -33.794\n",
      "No. Observations:                  15   AIC:                             73.59\n",
      "Df Residuals:                      12   BIC:                             75.71\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept    147.9560      8.876     16.669      0.000     128.617     167.295\n",
      "literacy      -2.5550      0.116    -21.950      0.000      -2.809      -2.301\n",
      "labor          3.2195      0.334      9.643      0.000       2.492       3.947\n",
      "==============================================================================\n",
      "Omnibus:                        0.492   Durbin-Watson:                   0.552\n",
      "Prob(Omnibus):                  0.782   Jarque-Bera (JB):                0.540\n",
      "Skew:                          -0.066   Prob(JB):                        0.763\n",
      "Kurtosis:                       2.080   Cond. No.                     1.23e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.23e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sahin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\scipy\\stats\\_stats_py.py:1772: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=15\n",
      "  warnings.warn(\"kurtosistest only valid for n>=20 ... continuing \"\n"
     ]
    }
   ],
   "source": [
    "res = vars_mor('TUR', dfs, vars)\n",
    "model = ols('mortality ~ literacy + labor', data=res).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af3d05f-26e8-4e21-8cc8-5df66f63f49e",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "\n",
    "For this question use Yahoo's Finance API for the following tickers:\n",
    "\n",
    "* Gold futures (GC=F)\n",
    "* Silver futures (SI=F)\n",
    "* Copper futures (HG=F)\n",
    "* Platinum futures (PL=F)\n",
    "\n",
    "1. Write the best linear regression model that explains gold futures closing prices in terms of opening prices of gold, silver, copper, and platinum futures.\n",
    "2. Repeat the same for silver, copper and platinum prices.\n",
    "3. Compare the models you obtained in Steps 1 and 2. Which model is better? How do you decide? Explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "1ce8fdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tickers_openning(x, ftickers, fticker_names):\n",
    "    tmp = {}\n",
    "    tmp['GCF_o'] = ftickers[0]['Open']\n",
    "    tmp['SIF_o'] = ftickers[1]['Open']\n",
    "    tmp['HGF_o'] = ftickers[2]['Open']\n",
    "    tmp['PLF_o'] = ftickers[3]['Open']\n",
    "    tmp[x[:-2]+x[-1]+'_c'] = ftickers[fticker_names.index(x)]['Close']\n",
    "\n",
    "    data = pd.DataFrame(tmp).dropna()\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "72a648a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "fticker_names = ['GC=F', 'SI=F', 'HG=F', 'PL=F']\n",
    "ftickers = [yf.download(ticker) for ticker in fticker_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "ae6f4cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GCF_o</th>\n",
       "      <th>SIF_o</th>\n",
       "      <th>HGF_o</th>\n",
       "      <th>PLF_o</th>\n",
       "      <th>GCF_c</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-08-30</th>\n",
       "      <td>273.899994</td>\n",
       "      <td>4.950000</td>\n",
       "      <td>0.8790</td>\n",
       "      <td>593.900024</td>\n",
       "      <td>273.899994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-08-31</th>\n",
       "      <td>274.799988</td>\n",
       "      <td>4.920000</td>\n",
       "      <td>0.8850</td>\n",
       "      <td>589.000000</td>\n",
       "      <td>278.299988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-09-01</th>\n",
       "      <td>277.000000</td>\n",
       "      <td>5.035000</td>\n",
       "      <td>0.8780</td>\n",
       "      <td>588.000000</td>\n",
       "      <td>277.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-09-05</th>\n",
       "      <td>275.799988</td>\n",
       "      <td>4.990000</td>\n",
       "      <td>0.8960</td>\n",
       "      <td>602.000000</td>\n",
       "      <td>275.799988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-09-06</th>\n",
       "      <td>274.200012</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>603.000000</td>\n",
       "      <td>274.200012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-01</th>\n",
       "      <td>1630.800049</td>\n",
       "      <td>19.125000</td>\n",
       "      <td>3.4945</td>\n",
       "      <td>959.799988</td>\n",
       "      <td>1645.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-02</th>\n",
       "      <td>1650.800049</td>\n",
       "      <td>19.780001</td>\n",
       "      <td>3.4985</td>\n",
       "      <td>960.200012</td>\n",
       "      <td>1645.699951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-03</th>\n",
       "      <td>1629.199951</td>\n",
       "      <td>19.235001</td>\n",
       "      <td>3.4455</td>\n",
       "      <td>933.400024</td>\n",
       "      <td>1627.300049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-04</th>\n",
       "      <td>1630.199951</td>\n",
       "      <td>19.980000</td>\n",
       "      <td>3.6370</td>\n",
       "      <td>969.799988</td>\n",
       "      <td>1672.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-07</th>\n",
       "      <td>1678.599976</td>\n",
       "      <td>20.570000</td>\n",
       "      <td>3.6450</td>\n",
       "      <td>964.700012</td>\n",
       "      <td>1678.900024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4865 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  GCF_o      SIF_o   HGF_o       PLF_o        GCF_c\n",
       "Date                                                               \n",
       "2000-08-30   273.899994   4.950000  0.8790  593.900024   273.899994\n",
       "2000-08-31   274.799988   4.920000  0.8850  589.000000   278.299988\n",
       "2000-09-01   277.000000   5.035000  0.8780  588.000000   277.000000\n",
       "2000-09-05   275.799988   4.990000  0.8960  602.000000   275.799988\n",
       "2000-09-06   274.200012   5.000000  0.9050  603.000000   274.200012\n",
       "...                 ...        ...     ...         ...          ...\n",
       "2022-11-01  1630.800049  19.125000  3.4945  959.799988  1645.000000\n",
       "2022-11-02  1650.800049  19.780001  3.4985  960.200012  1645.699951\n",
       "2022-11-03  1629.199951  19.235001  3.4455  933.400024  1627.300049\n",
       "2022-11-04  1630.199951  19.980000  3.6370  969.799988  1672.500000\n",
       "2022-11-07  1678.599976  20.570000  3.6450  964.700012  1678.900024\n",
       "\n",
       "[4865 rows x 5 columns]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[gcfc, sifc, hgfc, plfc] = [tickers_openning(x, ftickers, fticker_names) for x in fticker_names]\n",
    "gcfc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb8870a",
   "metadata": {},
   "source": [
    "### Linear regression models that explains GC = F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "794ee787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>GCF_c</td>      <th>  R-squared:         </th> <td>   0.878</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.878</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>1.168e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 07 Nov 2022</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:28:21</td>     <th>  Log-Likelihood:    </th> <td> -32183.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  4865</td>      <th>  AIC:               </th> <td>6.437e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  4861</td>      <th>  BIC:               </th> <td>6.440e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>  431.4786</td> <td>    8.453</td> <td>   51.046</td> <td> 0.000</td> <td>  414.907</td> <td>  448.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SIF_o</th>     <td>   49.1464</td> <td>    0.617</td> <td>   79.622</td> <td> 0.000</td> <td>   47.936</td> <td>   50.356</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HGF_o</th>     <td>  229.0768</td> <td>    4.668</td> <td>   49.074</td> <td> 0.000</td> <td>  219.925</td> <td>  238.228</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PLF_o</th>     <td>   -0.6946</td> <td>    0.011</td> <td>  -61.164</td> <td> 0.000</td> <td>   -0.717</td> <td>   -0.672</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>376.384</td> <th>  Durbin-Watson:     </th> <td>   0.023</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 874.776</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.479</td>  <th>  Prob(JB):          </th> <td>1.11e-190</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.844</td>  <th>  Cond. No.          </th> <td>3.78e+03</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 3.78e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  GCF_c   R-squared:                       0.878\n",
       "Model:                            OLS   Adj. R-squared:                  0.878\n",
       "Method:                 Least Squares   F-statistic:                 1.168e+04\n",
       "Date:                Mon, 07 Nov 2022   Prob (F-statistic):               0.00\n",
       "Time:                        23:28:21   Log-Likelihood:                -32183.\n",
       "No. Observations:                4865   AIC:                         6.437e+04\n",
       "Df Residuals:                    4861   BIC:                         6.440e+04\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept    431.4786      8.453     51.046      0.000     414.907     448.050\n",
       "SIF_o         49.1464      0.617     79.622      0.000      47.936      50.356\n",
       "HGF_o        229.0768      4.668     49.074      0.000     219.925     238.228\n",
       "PLF_o         -0.6946      0.011    -61.164      0.000      -0.717      -0.672\n",
       "==============================================================================\n",
       "Omnibus:                      376.384   Durbin-Watson:                   0.023\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              874.776\n",
       "Skew:                          -0.479   Prob(JB):                    1.11e-190\n",
       "Kurtosis:                       4.844   Cond. No.                     3.78e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 3.78e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = ols('GCF_c ~ SIF_o + HGF_o + PLF_o', data=gcfc).fit()\n",
    "display(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd10e5e8",
   "metadata": {},
   "source": [
    "### Linear regression models that explains SI = F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "346dd183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>SIF_c</td>      <th>  R-squared:         </th> <td>   0.898</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.898</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>1.431e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 07 Nov 2022</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:28:21</td>     <th>  Log-Likelihood:    </th> <td> -11843.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  4865</td>      <th>  AIC:               </th> <td>2.369e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  4861</td>      <th>  BIC:               </th> <td>2.372e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   -6.5914</td> <td>    0.129</td> <td>  -51.009</td> <td> 0.000</td> <td>   -6.845</td> <td>   -6.338</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>GCF_o</th>     <td>    0.0115</td> <td>    0.000</td> <td>   79.593</td> <td> 0.000</td> <td>    0.011</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HGF_o</th>     <td>   -0.4500</td> <td>    0.087</td> <td>   -5.174</td> <td> 0.000</td> <td>   -0.621</td> <td>   -0.280</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PLF_o</th>     <td>    0.0109</td> <td>    0.000</td> <td>   63.846</td> <td> 0.000</td> <td>    0.011</td> <td>    0.011</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>1300.011</td> <th>  Durbin-Watson:     </th> <td>   0.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>6397.420</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 1.200</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 8.080</td>  <th>  Cond. No.          </th> <td>5.44e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 5.44e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  SIF_c   R-squared:                       0.898\n",
       "Model:                            OLS   Adj. R-squared:                  0.898\n",
       "Method:                 Least Squares   F-statistic:                 1.431e+04\n",
       "Date:                Mon, 07 Nov 2022   Prob (F-statistic):               0.00\n",
       "Time:                        23:28:21   Log-Likelihood:                -11843.\n",
       "No. Observations:                4865   AIC:                         2.369e+04\n",
       "Df Residuals:                    4861   BIC:                         2.372e+04\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -6.5914      0.129    -51.009      0.000      -6.845      -6.338\n",
       "GCF_o          0.0115      0.000     79.593      0.000       0.011       0.012\n",
       "HGF_o         -0.4500      0.087     -5.174      0.000      -0.621      -0.280\n",
       "PLF_o          0.0109      0.000     63.846      0.000       0.011       0.011\n",
       "==============================================================================\n",
       "Omnibus:                     1300.011   Durbin-Watson:                   0.022\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             6397.420\n",
       "Skew:                           1.200   Prob(JB):                         0.00\n",
       "Kurtosis:                       8.080   Cond. No.                     5.44e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 5.44e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = ols('SIF_c ~ GCF_o + HGF_o + PLF_o', data=sifc).fit()\n",
    "display(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20409fb4",
   "metadata": {},
   "source": [
    "### Linear regression models that explains HG = F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "5c32b8ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>HGF_c</td>      <th>  R-squared:         </th> <td>   0.833</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.833</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   8061.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 07 Nov 2022</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:28:21</td>     <th>  Log-Likelihood:    </th> <td> -3073.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  4865</td>      <th>  AIC:               </th> <td>   6154.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  4861</td>      <th>  BIC:               </th> <td>   6180.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   -0.3248</td> <td>    0.026</td> <td>  -12.494</td> <td> 0.000</td> <td>   -0.376</td> <td>   -0.274</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>GCF_o</th>     <td>    0.0015</td> <td> 2.96e-05</td> <td>   49.046</td> <td> 0.000</td> <td>    0.001</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SIF_o</th>     <td>   -0.0129</td> <td>    0.002</td> <td>   -5.466</td> <td> 0.000</td> <td>   -0.018</td> <td>   -0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PLF_o</th>     <td>    0.0015</td> <td> 3.18e-05</td> <td>   46.056</td> <td> 0.000</td> <td>    0.001</td> <td>    0.002</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>644.458</td> <th>  Durbin-Watson:     </th> <td>   0.014</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 953.749</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.973</td>  <th>  Prob(JB):          </th> <td>7.87e-208</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.959</td>  <th>  Cond. No.          </th> <td>6.58e+03</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 6.58e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  HGF_c   R-squared:                       0.833\n",
       "Model:                            OLS   Adj. R-squared:                  0.833\n",
       "Method:                 Least Squares   F-statistic:                     8061.\n",
       "Date:                Mon, 07 Nov 2022   Prob (F-statistic):               0.00\n",
       "Time:                        23:28:21   Log-Likelihood:                -3073.2\n",
       "No. Observations:                4865   AIC:                             6154.\n",
       "Df Residuals:                    4861   BIC:                             6180.\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -0.3248      0.026    -12.494      0.000      -0.376      -0.274\n",
       "GCF_o          0.0015   2.96e-05     49.046      0.000       0.001       0.002\n",
       "SIF_o         -0.0129      0.002     -5.466      0.000      -0.018      -0.008\n",
       "PLF_o          0.0015   3.18e-05     46.056      0.000       0.001       0.002\n",
       "==============================================================================\n",
       "Omnibus:                      644.458   Durbin-Watson:                   0.014\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              953.749\n",
       "Skew:                           0.973   Prob(JB):                    7.87e-208\n",
       "Kurtosis:                       3.959   Cond. No.                     6.58e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 6.58e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = ols('HGF_c ~ GCF_o + SIF_o + PLF_o', data=hgfc).fit()\n",
    "display(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70623f84",
   "metadata": {},
   "source": [
    "### Linear regression models that explains PL = F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "b7c02dd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>PLF_c</td>      <th>  R-squared:         </th> <td>   0.781</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.780</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   5763.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 07 Nov 2022</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:28:22</td>     <th>  Log-Likelihood:    </th> <td> -31933.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  4865</td>      <th>  AIC:               </th> <td>6.387e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  4861</td>      <th>  BIC:               </th> <td>6.390e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>  524.4937</td> <td>    6.521</td> <td>   80.435</td> <td> 0.000</td> <td>  511.710</td> <td>  537.277</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>GCF_o</th>     <td>   -0.6276</td> <td>    0.010</td> <td>  -61.261</td> <td> 0.000</td> <td>   -0.648</td> <td>   -0.608</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SIF_o</th>     <td>   41.9496</td> <td>    0.657</td> <td>   63.839</td> <td> 0.000</td> <td>   40.661</td> <td>   43.238</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HGF_o</th>     <td>  207.9301</td> <td>    4.526</td> <td>   45.945</td> <td> 0.000</td> <td>  199.058</td> <td>  216.802</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>247.922</td> <th>  Durbin-Watson:     </th> <td>   0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 328.182</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.494</td>  <th>  Prob(JB):          </th> <td>5.45e-72</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.802</td>  <th>  Cond. No.          </th> <td>3.49e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 3.49e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  PLF_c   R-squared:                       0.781\n",
       "Model:                            OLS   Adj. R-squared:                  0.780\n",
       "Method:                 Least Squares   F-statistic:                     5763.\n",
       "Date:                Mon, 07 Nov 2022   Prob (F-statistic):               0.00\n",
       "Time:                        23:28:22   Log-Likelihood:                -31933.\n",
       "No. Observations:                4865   AIC:                         6.387e+04\n",
       "Df Residuals:                    4861   BIC:                         6.390e+04\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept    524.4937      6.521     80.435      0.000     511.710     537.277\n",
       "GCF_o         -0.6276      0.010    -61.261      0.000      -0.648      -0.608\n",
       "SIF_o         41.9496      0.657     63.839      0.000      40.661      43.238\n",
       "HGF_o        207.9301      4.526     45.945      0.000     199.058     216.802\n",
       "==============================================================================\n",
       "Omnibus:                      247.922   Durbin-Watson:                   0.018\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              328.182\n",
       "Skew:                           0.494   Prob(JB):                     5.45e-72\n",
       "Kurtosis:                       3.802   Cond. No.                     3.49e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 3.49e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = ols('PLF_c ~ GCF_o + SIF_o + HGF_o', data=plfc).fit()\n",
    "display(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c731d5c2",
   "metadata": {},
   "source": [
    "***\n",
    "Linear regression model that explains SI=F closing prices is better than the others because its R^2 value is larger.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6784ded-5ebb-492d-a244-62c7d42ec457",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "\n",
    "1. Write a function that takes a ticker symbol and returns a pandas dataframe that for each day puts a 1 when the closing price is higher than the opening price, a 0 when the closing price is lower than the opening price.\n",
    "2. Write the best logistic regression that predicts the time series you obtain from Step 1 for gold futures against the opening prices of gold, silver, copper, and platinum prices.\n",
    "3. Repeat the same for silver, copper, and platinum prices.\n",
    "4. Compare the models you obtained from Steps 2 and 3. Decide which is the best model, and explain your reasoning.\n",
    "5. Does any of the models provide a good fit? Explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "e67d2161-b332-47d0-8f16-b829520d55bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def openning_closing(ticker):\n",
    "    new_header = ticker[:-2]+ticker[-1]+'_co'\n",
    "\n",
    "    tmp = yf.download(ticker)\n",
    "    tmp[new_header] = 0\n",
    "\n",
    "    tmp[new_header][tmp['Close'] > tmp['Open']] = 1\n",
    "\n",
    "    tmp_co = pd.DataFrame(tmp[new_header])\n",
    "\n",
    "    return tmp_co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "3007f6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ticker_co_df(ticker, tickers_df):\n",
    "    df = pd.concat([tickers_df, openning_closing(ticker)], axis = 1)\n",
    "    df.dropna(inplace=True)\n",
    "    df.reset_index(inplace=True)\n",
    "    del df['Date']\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "1dccf784",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap(X, y, model):\n",
    "    res = []\n",
    "    for i in range(100):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75)\n",
    "        model.fit(X_train,y_train)\n",
    "        res.append(model.score(X_test,y_test))\n",
    "    tmp = sorted(res)[3:97]\n",
    "    return (min(tmp),max(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "ddf7ec78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model(df):\n",
    "    X = df.iloc[:, :4]\n",
    "    y = df.iloc[:, 5]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75)\n",
    "\n",
    "    model = LogisticRegression(max_iter=4000)\n",
    "    model.fit(X_train, y_train)\n",
    "    print(model.score(X_test, y_test))\n",
    "    \n",
    "    y_predict = model.predict(X_test)\n",
    "    print(confusion_matrix(y_test, y_predict))\n",
    "\n",
    "    print(bootstrap(X, y, model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "72d0972c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "fticker_names = ['GC=F', 'SI=F', 'HG=F', 'PL=F']\n",
    "ftickers = [yf.download(ticker) for ticker in fticker_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "8293e136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I used tickers_openning() function from question-2\n",
    "gcf_df = tickers_openning('GC=F', ftickers, fticker_names)\n",
    "sif_df = tickers_openning('SI=F', ftickers, fticker_names)\n",
    "hgf_df = tickers_openning('HG=F', ftickers, fticker_names)\n",
    "plf_df = tickers_openning('PL=F', ftickers, fticker_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "50968732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "0.5784716516023007\n",
      "[[614  75]\n",
      " [438  90]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sahin\\AppData\\Local\\Temp\\ipykernel_2116\\4014248705.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tmp[new_header][tmp['Close'] > tmp['Open']] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5546425636811833, 0.5916187345932621)\n"
     ]
    }
   ],
   "source": [
    "gcf_co_df = ticker_co_df('GC=F', gcf_df)\n",
    "print_model(gcf_co_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "b522b3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "0.6409202958093673\n",
      "[[777  13]\n",
      " [424   3]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sahin\\AppData\\Local\\Temp\\ipykernel_2116\\4014248705.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tmp[new_header][tmp['Close'] > tmp['Open']] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6409202958093673, 0.6803615447822514)\n"
     ]
    }
   ],
   "source": [
    "sif_co_df = ticker_co_df('SI=F', sif_df)\n",
    "print_model(sif_co_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "80e22a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "0.485620377978636\n",
      "[[571  18]\n",
      " [608  20]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sahin\\AppData\\Local\\Temp\\ipykernel_2116\\4014248705.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tmp[new_header][tmp['Close'] > tmp['Open']] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.48315529991783074, 0.5291700903861956)\n"
     ]
    }
   ],
   "source": [
    "hgf_co_df = ticker_co_df('HG=F', hgf_df)\n",
    "print_model(hgf_co_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "5599d23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "0.723911257189811\n",
      "[[808  79]\n",
      " [257  73]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sahin\\AppData\\Local\\Temp\\ipykernel_2116\\4014248705.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tmp[new_header][tmp['Close'] > tmp['Open']] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7091207888249794, 0.7460969597370584)\n"
     ]
    }
   ],
   "source": [
    "plf_co_df = ticker_co_df('PL=F', plf_df)\n",
    "print_model(plf_co_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d8596e",
   "metadata": {},
   "source": [
    "* Model for the PL=F seems to be the best according to their scores.\n",
    "* Values that are estimated to be 0 but actually 1 are too much in all four models. As a result, models that predicted 0 more get worse results. For this reason, we cannot say that any of the models provide a good fit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17365a32-866c-40d2-8ac9-5d0dcfaba69b",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "\n",
    "For this question use the following [data](https://archive.ics.uci.edu/ml/datasets/credit+approval):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "365d759b-b783-4539-96d0-8b6db6979c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/credit-screening/crx.data', header=None)\n",
    "\n",
    "fn = {'+': 1, '-': 0}\n",
    "\n",
    "X = credit.replace('?',0).iloc[:,[1,2,7,10,14]]\n",
    "y = credit.iloc[:,15].map(lambda x: fn.get(x,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ebfd20-ff04-43dc-b00d-508a110ff3b3",
   "metadata": {},
   "source": [
    "1. Split the data into training and test set.\n",
    "2. Write different logistic regression models predicting y against X.\n",
    "3. Construct [confusion matrices](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) on the test data set for these different models.\n",
    "4. Analyze these models. Explain which model is the best model you have found.\n",
    "5. Repeat Steps 1-4 several times. Does your best model stay as the best model? What should be the correct protocol to decide on the best model explaining the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "e750518d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "090412d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf07d13",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "d01d24ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7283236994219653"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = LogisticRegression()\n",
    "model1.fit(X_train, y_train)\n",
    "model1.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "2e4c42a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[86, 11],\n",
       "       [36, 40]], dtype=int64)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = model1.predict(X_test)\n",
    "confusion_matrix(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d30036",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "391abe95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([X_train, y_train], axis=1)\n",
    "df.columns = ['a','b','c','d','e','p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "92e2a7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.476230\n",
      "         Iterations 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>p</td>        <th>  No. Observations:  </th>  <td>   517</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   511</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     5</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Mon, 07 Nov 2022</td> <th>  Pseudo R-squ.:     </th>  <td>0.3073</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>23:28:43</td>     <th>  Log-Likelihood:    </th> <td> -246.21</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -355.43</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>3.223e-45</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   -1.9521</td> <td>    0.329</td> <td>   -5.931</td> <td> 0.000</td> <td>   -2.597</td> <td>   -1.307</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>a</th>         <td>    0.0100</td> <td>    0.010</td> <td>    1.039</td> <td> 0.299</td> <td>   -0.009</td> <td>    0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>b</th>         <td>    0.0282</td> <td>    0.024</td> <td>    1.177</td> <td> 0.239</td> <td>   -0.019</td> <td>    0.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>c</th>         <td>    0.1985</td> <td>    0.045</td> <td>    4.399</td> <td> 0.000</td> <td>    0.110</td> <td>    0.287</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>d</th>         <td>    0.3934</td> <td>    0.055</td> <td>    7.211</td> <td> 0.000</td> <td>    0.287</td> <td>    0.500</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>e</th>         <td>    0.0005</td> <td>    0.000</td> <td>    3.735</td> <td> 0.000</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                      p   No. Observations:                  517\n",
       "Model:                          Logit   Df Residuals:                      511\n",
       "Method:                           MLE   Df Model:                            5\n",
       "Date:                Mon, 07 Nov 2022   Pseudo R-squ.:                  0.3073\n",
       "Time:                        23:28:43   Log-Likelihood:                -246.21\n",
       "converged:                       True   LL-Null:                       -355.43\n",
       "Covariance Type:            nonrobust   LLR p-value:                 3.223e-45\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -1.9521      0.329     -5.931      0.000      -2.597      -1.307\n",
       "a              0.0100      0.010      1.039      0.299      -0.009       0.029\n",
       "b              0.0282      0.024      1.177      0.239      -0.019       0.075\n",
       "c              0.1985      0.045      4.399      0.000       0.110       0.287\n",
       "d              0.3934      0.055      7.211      0.000       0.287       0.500\n",
       "e              0.0005      0.000      3.735      0.000       0.000       0.001\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = smf.logit('p ~ a + b + c + d + e', data=df).fit()\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d282f027",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "1f9a2c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.513398\n",
      "         Iterations 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>15</td>        <th>  No. Observations:  </th>  <td>   517</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   512</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     4</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Mon, 07 Nov 2022</td> <th>  Pseudo R-squ.:     </th>  <td>0.2532</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>23:28:43</td>     <th>  Log-Likelihood:    </th> <td> -265.43</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -355.43</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>7.463e-38</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>     <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1</th>  <td>   -0.0411</td> <td>    0.006</td> <td>   -7.376</td> <td> 0.000</td> <td>   -0.052</td> <td>   -0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2</th>  <td>   -0.0108</td> <td>    0.023</td> <td>   -0.469</td> <td> 0.639</td> <td>   -0.056</td> <td>    0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7</th>  <td>    0.2091</td> <td>    0.043</td> <td>    4.809</td> <td> 0.000</td> <td>    0.124</td> <td>    0.294</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10</th> <td>    0.3625</td> <td>    0.051</td> <td>    7.154</td> <td> 0.000</td> <td>    0.263</td> <td>    0.462</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>14</th> <td>    0.0004</td> <td>    0.000</td> <td>    3.377</td> <td> 0.001</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                     15   No. Observations:                  517\n",
       "Model:                          Logit   Df Residuals:                      512\n",
       "Method:                           MLE   Df Model:                            4\n",
       "Date:                Mon, 07 Nov 2022   Pseudo R-squ.:                  0.2532\n",
       "Time:                        23:28:43   Log-Likelihood:                -265.43\n",
       "converged:                       True   LL-Null:                       -355.43\n",
       "Covariance Type:            nonrobust   LLR p-value:                 7.463e-38\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "1             -0.0411      0.006     -7.376      0.000      -0.052      -0.030\n",
       "2             -0.0108      0.023     -0.469      0.639      -0.056       0.034\n",
       "7              0.2091      0.043      4.809      0.000       0.124       0.294\n",
       "10             0.3625      0.051      7.154      0.000       0.263       0.462\n",
       "14             0.0004      0.000      3.377      0.001       0.000       0.001\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = sm.Logit(y_train, X_train).fit()\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "d5064559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[78, 19],\n",
       "       [31, 45]], dtype=int64)"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict3 = model3.predict(X_test)\n",
    "y_predict3 = np.where(y_predict3 > 0.5, 1, 0)\n",
    "confusion_matrix(y_test, y_predict3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf48bf9",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "8afaa164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5227994227994228, 0.028089887640449507)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4 = DecisionTreeRegressor()\n",
    "model4.fit(X_train, y_train)\n",
    "bootstrap(X, y, model4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "61a89fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[92,  5],\n",
       "       [ 7, 69]], dtype=int64)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict4 = model4.predict(X_test)\n",
    "confusion_matrix(y_test, y_predict4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b75dda7",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "a5811654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.020744153891729677, 0.28762742519796947)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5 = LinearRegression()\n",
    "model5.fit(X_train, y_train)\n",
    "bootstrap(X, y, model5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "f61f03ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[88,  9],\n",
       "       [41, 35]], dtype=int64)"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict5 = model5.predict(X_test)\n",
    "y_predict5 = np.where(y_predict5 > 0.5, 1, 0)\n",
    "confusion_matrix(y_test, y_predict5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f1b1e9",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8662215",
   "metadata": {},
   "source": [
    "Binary logistic regression model is the best model because y has 2 values (1 and 0). DecisionTreeRegressor() predicts y better than the others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc16b8c",
   "metadata": {},
   "source": [
    "What should be the correct protocol to decide on the best model explaining the data?\n",
    "* $R^2$-score of the model should be large,\n",
    "* p-values of the model coefficients should be small\n",
    "* the diagonal of the confusion matrix should have the largest numbers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "8e8271cb67d71434d71d7359a5244618f962c24c33d897b4dd8966bfba9a1715"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
